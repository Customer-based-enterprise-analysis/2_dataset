{"cells":[{"cell_type":"code","execution_count":null,"id":"6b13b096","metadata":{"id":"6b13b096"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from matplotlib import rc\n","import matplotlib.pyplot as plt \n","rc('font',family='Malgun Gothic') # 한글\n","plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호\n","\n","import os\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","from IPython.core.display import HTML\n","import time\n","import re"]},{"cell_type":"markdown","id":"36778590","metadata":{"id":"36778590"},"source":["# <font color=red>__데이터 불러오기__</font>"]},{"cell_type":"code","execution_count":null,"id":"4491b551","metadata":{"id":"4491b551"},"outputs":[],"source":["# 파일 불러와서 변수에 저장\n","path = './dataset'\n","file_list = os.listdir(path)\n","\n","data_li = []\n","for file in file_list:\n","    data = pd.read_csv(f'dataset/{file}',encoding='cp949')\n","    file_name = file.replace('.txt','')\n","    globals()[file_name] = data\n","    data_li.append(file_name)"]},{"cell_type":"code","execution_count":null,"id":"a4bc7804","metadata":{"id":"a4bc7804"},"outputs":[],"source":["# purprd 구매일자 type 변경 및 년, 반기, 분기, 요일 추가\n","purprd['구매일자'] = pd.to_datetime(purprd['구매일자'], format='%Y%m%d')\n","purprd['year'] = purprd['구매일자'].dt.year\n","purprd['quarter'] = purprd['구매일자'].dt.quarter\n","purprd['weekday'] = purprd['구매일자'].dt.weekday # 월 0 ~ 일 6\n","\n","def to_half(year,quarter):\n","    if (year==2014) & (quarter in [1,2]):\n","        return 1\n","    elif (year==2014) & (quarter in [3,4]):\n","        return 2\n","    elif (year==2015) & (quarter in [1,2]):\n","        return 3\n","    else:\n","        return 4\n","        \n","purprd['half'] = purprd.apply(lambda x: to_half(x['year'], x['quarter']), axis=1)"]},{"cell_type":"code","execution_count":null,"id":"c6c86228","metadata":{"id":"c6c86228"},"outputs":[],"source":["# 기존고객 => 매 분기 1회 이상 구매한 고객으로 한정\n","# 기존고객만 남긴 dataframe 생성\n","all_cust = pd.pivot_table(purprd,\n","                         index='고객번호',\n","                         columns='half',\n","                         values='구매금액',\n","                         aggfunc='sum')\n","\n","existing_cust_idx = all_cust.dropna().index.tolist() # 기존고객 고객번호\n","\n","for data in data_li:\n","    try:\n","        globals()[data] = globals()[data].query(f'고객번호 == {existing_cust_idx}')\n","    except:\n","        pass"]},{"cell_type":"code","execution_count":null,"id":"d64536d7","metadata":{"id":"d64536d7"},"outputs":[],"source":["# 연령대 묶어줌\n","def cat_age(age):\n","    if age == '19세이하':\n","        return 10\n","    elif age in ['20세~24세', '25세~29세']:\n","        return 20\n","    elif age in ['30세~34세', '35세~39세']:\n","        return 30\n","    elif age in ['40세~44세', '45세~49세']:\n","        return 40\n","    elif age in ['50세~54세', '55세~59세']:\n","        return 50\n","    else:\n","        return 60\n","    \n","cust['연령대'] = cust['연령대'].apply(lambda x: cat_age(x))"]},{"cell_type":"markdown","id":"499aa410","metadata":{"id":"499aa410"},"source":["# <font color=red>__종속변수__</font>"]},{"cell_type":"code","execution_count":null,"id":"6992f0e4","metadata":{"id":"6992f0e4"},"outputs":[],"source":["# 종속변수\n","def get_label(p1, p2):\n","    \"\"\"\n","    전체 매출 증감율을 고려한 고객별 매출 증감율(반기 기준)\n","    -> 감소고객 : 1\n","    -> 증가고객 : 0\n","    \"\"\"\n","    sales = pd.pivot_table(purprd,index='고객번호', # 고객별 반기 매출\n","                              columns = 'half',\n","                              values = '구매금액',\n","                              aggfunc= 'sum')\n","    rate_variation = (sum(sales[int(p2)])-sum(sales[int(p1)]))/sum(sales[int(p1)]) # 전체 매출 증감율\n","    sales[f'y'] = (sales[int(p2)] - sales[int(p1)])/sales[int(p1)]/rate_variation # 고객별 매출 증감율\n","    \n","    def to_label(sales_variation): # 매출 감소 고객 : 1\n","        if sales_variation >= 0:\n","            return 0\n","        else:\n","            return 1\n","    \n","    sales[f'y'] = sales[f'y'].apply(lambda x: to_label(x))\n","    sales = sales[[f'y']]\n","    return sales"]},{"cell_type":"markdown","id":"0eadeb13","metadata":{"id":"0eadeb13"},"source":["# <font color=red>__독립변수__</font>"]},{"cell_type":"markdown","id":"f313c1dd","metadata":{"id":"f313c1dd"},"source":["# 1) membership"]},{"cell_type":"code","execution_count":null,"id":"1d856433","metadata":{"id":"1d856433"},"outputs":[],"source":["# membership 가입 개수\n","def membership_count():\n","    membership_cust = pd.pivot_table(membership,\n","                                      index='고객번호',\n","                                      columns='멤버십명',\n","                                      values='가입년월',\n","                                      aggfunc='count').fillna(0)\n","    membership_cust['가입개수'] = membership_cust.sum(axis=1)\n","    return membership_cust[['가입개수']]"]},{"cell_type":"code","execution_count":null,"id":"3c4b7e32","metadata":{"id":"3c4b7e32"},"outputs":[],"source":["# 최초 membership 가입년도\n","def membership_date():\n","    membership['가입년월'] = pd.to_datetime(membership['가입년월'], format='%Y%m')\n","    membership['가입년도'] = membership['가입년월'].dt.year\n","\n","    first_membership_date = pd.pivot_table(membership,\n","                                    index='고객번호',\n","                                    values='가입년도',\n","                                    aggfunc='min')\n","    return first_membership_date"]},{"cell_type":"markdown","id":"4a6808c3","metadata":{"id":"4a6808c3"},"source":["# 2) channel"]},{"cell_type":"code","execution_count":null,"id":"20da220c","metadata":{"id":"20da220c"},"outputs":[],"source":["# app login 횟수\n","def app_count():\n","    channel_count = pd.pivot_table(channel,\n","                  index='고객번호',\n","                  columns='제휴사',\n","                  values='이용횟수')\n","\n","    channel_count['APP로그인횟수'] = channel_count[channel_count.columns[channel_count.columns.str.contains('APP')]].sum(axis=1)\n","    return channel_count[['APP로그인횟수']]"]},{"cell_type":"markdown","id":"8dacd130","metadata":{"id":"8dacd130"},"source":["# 3) compuse"]},{"cell_type":"code","execution_count":null,"id":"d64e2ca5","metadata":{"id":"d64e2ca5"},"outputs":[],"source":["# B제휴사 경쟁사 이용률\n","def B_compuse_rate():\n","    compuse_count = pd.pivot_table(compuse,\n","                    index='고객번호',\n","                    columns='경쟁사',\n","                    values='제휴사',\n","                    aggfunc='count').fillna(0)\n","    compuse_count['c_B'] = compuse_count['B01'] + compuse_count['B02']\n","\n","    purprd_count = pd.pivot_table(purprd.drop_duplicates(subset='영수증번호'),\n","                                  index='고객번호',\n","                                  columns='제휴사',\n","                                  values='영수증번호',\n","                                  aggfunc='count').fillna(0)\n","\n","    compuse_count = compuse_count.join(purprd_count)\n","\n","    compuse_count[f'c_B_rate'] = round(compuse_count['c_B']/(compuse_count['c_B']+compuse_count['B'])*100, 2)\n","    return compuse_count[['c_B_rate']]"]},{"cell_type":"markdown","id":"c1771a38","metadata":{"id":"c1771a38"},"source":["#### prodcat"]},{"cell_type":"code","execution_count":null,"id":"55755be6","metadata":{"id":"55755be6"},"outputs":[],"source":["# 상품분류 - 대분류, 구매목적분류 추가(수작업)\n","cat_name = pd.read_excel('상품분류.xlsx', index_col=0)[['소분류코드','대분류','구매목적분류']]\n","prodcat = pd.merge(prodcat, cat_name, on=['소분류코드'])\n","purprd = pd.merge(purprd, prodcat[['소분류코드','중분류명','소분류명','대분류','구매목적분류']])"]},{"cell_type":"markdown","id":"c4977047","metadata":{"id":"c4977047"},"source":["# 5) purprd"]},{"cell_type":"code","execution_count":null,"id":"711be4c6","metadata":{"id":"711be4c6"},"outputs":[],"source":["### 비율 계산\n","def to_rate(df, name):\n","    total = df.sum(axis=1)\n","    for col in df.columns:\n","        df[f'{col}_{name}_rate'] = round(df[col]/total*100, 2)\n","        df.drop(col, axis=1, inplace=True)\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"0f674e44","metadata":{"id":"0f674e44"},"outputs":[],"source":["# 선매품, 편의품 구매금액 비중\n","def purpose_cat_amount(p1, p2):\n","    purpose_cat = pd.pivot_table(purprd.query(f'half==[{p1},{p2}]'),\n","                                      index='고객번호',\n","                                      columns='구매목적분류',\n","                                      values='구매금액',\n","                                      aggfunc='sum').fillna(0)\n","    to_rate(purpose_cat, 'amount')\n","\n","    purpose_cat.drop('전문품_amount_rate',axis=1,inplace=True)\n","    return purpose_cat"]},{"cell_type":"code","execution_count":null,"id":"cad34009","metadata":{"id":"cad34009"},"outputs":[],"source":["# 대분류별 구매횟수 비중\n","def major_cat_count(p1, p2):\n","    major_cat_count = pd.pivot_table(purprd.query(f'half==[{p1},{p2}]'),\n","                                      index='고객번호',\n","                                      columns='대분류',\n","                                      values='구매금액',\n","                                      aggfunc='count').fillna(0)\n","\n","    to_rate(major_cat_count, 'count')\n","    return major_cat_count[['미용품_count_rate','스포츠레저_count_rate','패션잡화_count_rate',\\\n","                    '의류_count_rate','인테리어_count_rate']]"]},{"cell_type":"code","execution_count":null,"id":"694637ff","metadata":{"id":"694637ff"},"outputs":[],"source":["# 대분류별 구매금액 비중\n","def major_cat_amount(p1, p2):\n","    major_cat_amount = pd.pivot_table(purprd.query(f'half==[{p1},{p2}]'),\n","                                      index='고객번호',\n","                                      columns='대분류',\n","                                      values='구매금액',\n","                                      aggfunc='sum').fillna(0)\n","\n","    to_rate(major_cat_amount, 'amount')\n","    return major_cat_amount[['가공식품_amount_rate','교육문화_amount_rate','기타_amount_rate',\\\n","                     '신선식품_amount_rate','일상용품_amount_rate']]"]},{"cell_type":"code","execution_count":null,"id":"61fce654","metadata":{"id":"61fce654"},"outputs":[],"source":["# 제휴사별 구매횟수 비중\n","def affiliate_count(p1, p2):\n","    affiliate_count = pd.pivot_table(purprd.query(f'half==[{p1},{p2}]'),\n","                                      index='고객번호',\n","                                      columns='제휴사',\n","                                      values='구매금액',\n","                                      aggfunc='count').fillna(0)\n","    to_rate(affiliate_count, 'count')\n","    return affiliate_count"]},{"cell_type":"code","execution_count":null,"id":"abbaccc1","metadata":{"id":"abbaccc1"},"outputs":[],"source":["# 제휴사별 구매금액 비중\n","def affiliate_mount(p1, p2):\n","    affiliate_mount = pd.pivot_table(purprd.query(f'half==[{p1},{p2}]'),\n","                                      index='고객번호',\n","                                      columns='제휴사',\n","                                      values='구매금액',\n","                                      aggfunc='sum').fillna(0)\n","    to_rate(affiliate_mount, 'mount')\n","    return affiliate_mount"]},{"cell_type":"code","execution_count":null,"id":"38d4b5fd","metadata":{"id":"38d4b5fd"},"outputs":[],"source":["### 증감율 계산(purprd, 구매금액 기준)\n","def purprd_amount_pv(col, period1, period2):\n","    for i in [period1, period2]:\n","        globals()[f'p{i}'] = pd.pivot_table(purprd.query(f'half=={i}'),\n","                                           index='고객번호',\n","                                           columns=col,\n","                                           values='구매금액',\n","                                           aggfunc='sum').fillna(0)\n","        \n","    variation = (globals()[f'p{period2}'] - globals()[f'p{period1}'])/globals()[f'p{period1}']*100\n","    return variation.replace({np.inf:100, np.nan:0})"]},{"cell_type":"markdown","id":"0aee6360","metadata":{"id":"0aee6360"},"source":["# <font color=red>__dataset__</font>"]},{"cell_type":"code","execution_count":null,"id":"5e595de0","metadata":{"id":"5e595de0"},"outputs":[],"source":["def make_dataset(p1, p2, p3):\n","    dataset = pd.DataFrame(cust[['연령대','성별']]).join([ # 연령대, 성별    -> - / label\n","        membership_count(), # membership 가입 개수                           \n","        membership_date(), # 최초 membership 가입년도                        -> label\n","        app_count(), # app login 횟수                                        \n","        B_compuse_rate(), # B제휴사 경쟁사 이용률                            \n","        purpose_cat_amount(p1, p2), # 선매품, 편의품 구매금액 비중           \n","        major_cat_count(p1, p2), # 대분류별 구매횟수 비중(미용품,스포츠레저,패션잡화,의류,인테리어) \n","        major_cat_amount(p1, p2), # 대분류별 구매금액 비중(가공식품,교육문화,기타,신선식품,일상용품)\n","        affiliate_count(p1, p2), # 제휴사별 구매횟수 비중\n","        affiliate_mount(p1, p2), # 제휴사별 구매금액 비중\n","        purprd_amount_pv('구매목적분류', p1, p2)[['편의품']], # 편의품 구매금액 증감율\n","        purprd_amount_pv('대분류', p1, p2)[['가공식품','미용품','스포츠레저','의류']], # 대분류별 구매금액 증감율\n","        purprd_amount_pv('제휴사', p1, p2)[['A']], # 제휴사별 구매금액 증감율\n","        get_label(p1, p3)]) # 종속변수\n","    dataset.fillna(0, inplace=True)\n","    return dataset\n","\n","dataset1 = make_dataset(1,2,3) # train(train / vaild)\n","dataset2 = make_dataset(2,3,4) # test"]},{"cell_type":"code","execution_count":null,"id":"34c58968","metadata":{"id":"34c58968"},"outputs":[],"source":["# Labelencoder\n","from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","le_cols = ['성별','가입년도']\n","\n","for col in le_cols:\n","    dataset1[col] = le.fit_transform(dataset1[col])\n","    dataset2[col] = le.fit_transform(dataset2[col])"]},{"cell_type":"code","execution_count":null,"id":"f4f5ad0b","metadata":{"id":"f4f5ad0b"},"outputs":[],"source":["# Category\n","# cat_cols = dataset1.columns[4:-7].tolist()\n","\n","# def to_cat(df, col, n=6):\n","#     data = df[col].astype(float)\n","#     cat_data = pd.cut(data, n, labels=list(range(1, n+1)))\n","#     return cat_data\n","\n","# for col in cat_cols:\n","#     dataset1[col] = to_cat(dataset1, col)\n","#     dataset2[col] = to_cat(dataset2, col)"]},{"cell_type":"code","execution_count":null,"id":"8c50b8e7","metadata":{"id":"8c50b8e7"},"outputs":[],"source":["# # Category(증감율 => 마이너스 / 플러스 나누고 카테고리)\n","# cat_plus_cols = ['편의품', '가공식품', '미용품', '스포츠레저', '의류', 'A']\n","\n","# def to_cat_plus(df, col, n1=3, n2=3):\n","#     data = df[col]\n","    \n","#     data_minus = data[data<=0]\n","#     data_minus_cut = pd.cut(data_minus,n1,labels=list(range(1,n1+1)))\n","\n","#     data_plus = data[0<data]\n","#     data_plus_cut = pd.cut(data_plus,n2,labels=list(range(n1+1,n1+n2+1)))\n","    \n","#     return pd.concat([data_minus_cut,data_plus_cut])\n","\n","# for col in cat_plus_cols:\n","#     dataset1[col] = to_cat_plus(dataset1, col)\n","#     dataset2[col] = to_cat_plus(dataset2, col)"]},{"cell_type":"code","execution_count":null,"id":"3e347ae5","metadata":{"id":"3e347ae5"},"outputs":[],"source":["# Standardscaler\n","# from sklearn.preprocessing import MinMaxScaler\n","\n","# sc = MinMaxScaler()\n","\n","# for col in sc_cols:\n","#     dataset1[col] = sc.fit_transform(dataset1[[col]])\n","#     dataset2[col] = sc.fit_transform(dataset2[[col]])"]},{"cell_type":"code","execution_count":null,"id":"c8b5f4f5","metadata":{"id":"c8b5f4f5"},"outputs":[],"source":["for col in dataset1.dtypes[dataset1.dtypes=='category'].index:\n","    dataset1[col] = dataset1[col].astype(int)\n","    dataset2[col] = dataset2[col].astype(int)"]},{"cell_type":"code","execution_count":null,"id":"dcf2c67f","metadata":{"id":"dcf2c67f"},"outputs":[],"source":["dataset1.to_csv('dataset1.csv')\n","dataset2.to_csv('dataset2.csv')\n","\n","dataset1 = pd.read_csv('dataset1.csv', index_col=0)\n","dataset2 = pd.read_csv('dataset2.csv', index_col=0)"]},{"cell_type":"code","execution_count":null,"id":"fb29414d","metadata":{"id":"fb29414d"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X = dataset1.drop('y', axis=1)\n","y = dataset1['y']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                   test_size=0.3, # vaild\n","                                                   random_state=1004)"]},{"cell_type":"code","execution_count":null,"id":"631a684c","metadata":{"id":"631a684c"},"outputs":[],"source":["# #최종 TEST시 사용\n","# X_train = dataset1.drop('y', axis=1)\n","# y_train = dataset1['y']\n","\n","# X_test = dataset2.drop('y', axis=1)\n","# y_test = dataset2['y']"]},{"cell_type":"code","execution_count":null,"id":"7e45b19d","metadata":{"scrolled":false,"id":"7e45b19d","outputId":"71010ee4-f6ae-4078-fd6c-723331c23790"},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'max_depth': 3}</td>\n","      <td>2</td>\n","      <td>0.692658</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'max_depth': 5}</td>\n","      <td>1</td>\n","      <td>0.694299</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DecisionTreeClassifier 최적 하이퍼 파라미터: {'max_depth': 5}\n","DecisionTreeClassifier 최고 정확도:0.6943\n","테스트 데이터 세트 정확도:0.7010\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n","      <td>6</td>\n","      <td>0.707432</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'max_depth': 7, 'n_estimators': 200}</td>\n","      <td>5</td>\n","      <td>0.707656</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'max_depth': 7, 'n_estimators': 300}</td>\n","      <td>9</td>\n","      <td>0.706686</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n","      <td>1</td>\n","      <td>0.711088</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'max_depth': 9, 'n_estimators': 200}</td>\n","      <td>2</td>\n","      <td>0.710939</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'max_depth': 9, 'n_estimators': 300}</td>\n","      <td>3</td>\n","      <td>0.709670</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>{'max_depth': 11, 'n_estimators': 100}</td>\n","      <td>7</td>\n","      <td>0.707208</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>{'max_depth': 11, 'n_estimators': 200}</td>\n","      <td>8</td>\n","      <td>0.707208</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>{'max_depth': 11, 'n_estimators': 300}</td>\n","      <td>4</td>\n","      <td>0.708999</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["RandomForestClassifier 최적 하이퍼 파라미터: {'max_depth': 9, 'n_estimators': 100}\n","RandomForestClassifier 최고 정확도:0.7111\n","테스트 데이터 세트 정확도:0.7133\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'C': 1, 'penalty': 'l1'}</td>\n","      <td>9</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'C': 1, 'penalty': 'l2'}</td>\n","      <td>3</td>\n","      <td>0.654081</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'C': 1, 'penalty': 'elasticnet'}</td>\n","      <td>10</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'C': 1, 'penalty': 'none'}</td>\n","      <td>4</td>\n","      <td>0.654007</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'C': 10, 'penalty': 'l1'}</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'C': 10, 'penalty': 'l2'}</td>\n","      <td>2</td>\n","      <td>0.654231</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>{'C': 10, 'penalty': 'elasticnet'}</td>\n","      <td>12</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>{'C': 10, 'penalty': 'none'}</td>\n","      <td>4</td>\n","      <td>0.654007</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>{'C': 100, 'penalty': 'l1'}</td>\n","      <td>13</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>{'C': 100, 'penalty': 'l2'}</td>\n","      <td>8</td>\n","      <td>0.653559</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>{'C': 100, 'penalty': 'elasticnet'}</td>\n","      <td>14</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>{'C': 100, 'penalty': 'none'}</td>\n","      <td>4</td>\n","      <td>0.654007</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>{'C': 1000, 'penalty': 'l1'}</td>\n","      <td>15</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>{'C': 1000, 'penalty': 'l2'}</td>\n","      <td>1</td>\n","      <td>0.654529</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>{'C': 1000, 'penalty': 'elasticnet'}</td>\n","      <td>16</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>{'C': 1000, 'penalty': 'none'}</td>\n","      <td>4</td>\n","      <td>0.654007</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["LogisticRegression 최적 하이퍼 파라미터: {'C': 1000, 'penalty': 'l2'}\n","LogisticRegression 최고 정확도:0.6545\n","테스트 데이터 세트 정확도:0.6590\n","[12:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:34:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[12:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300}</td>\n","      <td>1</td>\n","      <td>0.707507</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300}</td>\n","      <td>2</td>\n","      <td>0.702209</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 300}</td>\n","      <td>4</td>\n","      <td>0.697732</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}</td>\n","      <td>3</td>\n","      <td>0.702209</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}</td>\n","      <td>5</td>\n","      <td>0.696314</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}</td>\n","      <td>6</td>\n","      <td>0.693404</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["XGBClassifier 최적 하이퍼 파라미터: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300}\n","XGBClassifier 최고 정확도:0.7075\n","테스트 데이터 세트 정확도:0.7131\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300}</td>\n","      <td>1</td>\n","      <td>0.706014</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300}</td>\n","      <td>3</td>\n","      <td>0.701314</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 300}</td>\n","      <td>2</td>\n","      <td>0.701761</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}</td>\n","      <td>4</td>\n","      <td>0.700568</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}</td>\n","      <td>6</td>\n","      <td>0.694822</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}</td>\n","      <td>5</td>\n","      <td>0.696911</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["LGBMClassifier 최적 하이퍼 파라미터: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300}\n","LGBMClassifier 최고 정확도:0.7060\n","테스트 데이터 세트 정확도:0.7138\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>rank_test_score</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'learning_rate': 0.05, 'n_estimators': 100}</td>\n","      <td>1</td>\n","      <td>0.708477</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'learning_rate': 0.05, 'n_estimators': 200}</td>\n","      <td>2</td>\n","      <td>0.708253</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'learning_rate': 0.05, 'n_estimators': 300}</td>\n","      <td>3</td>\n","      <td>0.708104</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'learning_rate': 0.05, 'n_estimators': 400}</td>\n","      <td>5</td>\n","      <td>0.706462</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'learning_rate': 0.05, 'n_estimators': 500}</td>\n","      <td>6</td>\n","      <td>0.705790</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n","      <td>4</td>\n","      <td>0.708029</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n","      <td>7</td>\n","      <td>0.704447</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>{'learning_rate': 0.1, 'n_estimators': 300}</td>\n","      <td>8</td>\n","      <td>0.703179</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>{'learning_rate': 0.1, 'n_estimators': 400}</td>\n","      <td>9</td>\n","      <td>0.700866</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>{'learning_rate': 0.1, 'n_estimators': 500}</td>\n","      <td>10</td>\n","      <td>0.699896</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["GradientBoostingClassifier 최적 하이퍼 파라미터: {'learning_rate': 0.05, 'n_estimators': 100}\n","GradientBoostingClassifier 최고 정확도:0.7085\n","테스트 데이터 세트 정확도:0.7117\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from xgboost import XGBClassifier, plot_importance\n","from lightgbm import LGBMClassifier, plot_importance\n","# from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","\n","# 객체 생성\n","dct_clf = DecisionTreeClassifier(criterion = 'entropy')\n","rf_clf = RandomForestClassifier()\n","lr_clf = LogisticRegression()\n","xgb_clf = XGBClassifier()\n","lgb_clf = LGBMClassifier()\n","gb_clf = GradientBoostingClassifier()\n","# svm_clf = SVC(probability=True)\n","\n","# 파라미터 설정\n","dct_parameters = {'max_depth':[3,5], }\n","rf_parameters = {'n_estimators':[100,200,300], 'max_depth':[7,9,11]}\n","lr_parameters = { \"penalty\":['l1', 'l2', 'elasticnet', 'none'], 'C': [ 1, 10, 100, 1000]}\n","xgb_parameters = {'n_estimators':[300], 'learning_rate':[0.05, 0.1], 'max_depth':[4,5,6]}\n","lgb_parameters = {'n_estimators':[300], 'learning_rate':[0.05, 0.1], 'max_depth':[4,5,6]}\n","gb_parameters = {'n_estimators':[100,200,300,400,500],'learning_rate':[0.05,0.1]}\n","# svm_parameters = {'kernel':['linear', 'rbf'], 'C':[2,4,6,8,10]}\n","\n","clf_param = [(dct_clf,dct_parameters),(rf_clf,rf_parameters),(lr_clf,lr_parameters),\n","             (xgb_clf,xgb_parameters),(lgb_clf,lgb_parameters),(gb_clf,gb_parameters),\n","             ] # , (svm_clf,svm_parameters)\n","\n","for clf, parameter in clf_param:\n","    grid_clf = GridSearchCV(clf, param_grid=parameter, scoring='accuracy', cv=3, refit=True)\n","    grid_clf.fit(X_train, y_train)\n","    \n","    # 교차검증 결과 출력\n","    class_name = clf.__class__.__name__\n","    scores_df = pd.DataFrame(grid_clf.cv_results_)\n","    display(HTML(scores_df[['params','rank_test_score','mean_test_score']].to_html()))\n","    print(f'{class_name} 최적 하이퍼 파라미터:', grid_clf.best_params_)\n","    print('{0} 최고 정확도:{1:.4f}'.format(class_name,grid_clf.best_score_))\n","    \n","    # x_test에 최적 하이퍼 파라미터 적용하여 분석한 결과\n","    best_clf = grid_clf.best_estimator_\n","    pred = best_clf.predict(X_test)\n","    pred_proba = best_clf.predict_proba(X_test)[:,1]\n","    print('테스트 데이터 세트 정확도:{:.4f}'.format(accuracy_score(y_test,pred)))"]},{"cell_type":"markdown","id":"4525318d","metadata":{"id":"4525318d"},"source":["# <font color=red>__아노바분석🤖__</font>"]},{"cell_type":"code","execution_count":1,"id":"d0e25fc6","metadata":{"id":"d0e25fc6","executionInfo":{"status":"ok","timestamp":1648794449506,"user_tz":-540,"elapsed":6,"user":{"displayName":"조현정","userId":"02569453026248958222"}}},"outputs":[],"source":["# # anova pvalue 함수👻\n","from scipy import stats\n","\n","def anova_test(dataset):\n","    num = 1\n","    data = dataset.drop('y',axis=1)\n","    target = dataset.y\n","    data = data.join(target)\n","    \n","    for n in range(len(data.columns[:-1])):\n","        grps = [data[data.columns[-1]].tolist() for _, data in data.groupby(data.columns[n])]        \n","        F, p = stats.f_oneway(*grps)\n","        if p >= 0.05:\n","            print(num, data.columns[n],':', round(p,3),'무의미')\n","        elif p < 0.05:\n","            print(num, data.columns[n],':', round(p,3),'😊')\n","        num += 1\n","            \n","anova_test(dataset1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"2.dataset_1.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}